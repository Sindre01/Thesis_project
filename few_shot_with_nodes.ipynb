{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "605d132a-e3b2-42ee-82a2-50ccefbc9139",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf93b4f-f9b0-4929-bd2c-4bb7688d8576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in ./.local/lib/python3.11/site-packages (24.3.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.11/site-packages (4.47.0)\n",
      "Requirement already satisfied: torch in ./.local/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: accelerate in ./.local/lib/python3.11/site-packages (1.2.0)\n",
      "Requirement already satisfied: bitsandbytes in ./.local/lib/python3.11/site-packages (0.45.0)\n",
      "Requirement already satisfied: filelock in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from transformers) (3.13.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in ./.local/lib/python3.11/site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.11/site-packages (from transformers) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /cluster/software/EL9/easybuild/software/PyYAML/6.0.1-GCCcore-13.2.0/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.local/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /cluster/software/EL9/easybuild/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./.local/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./.local/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./.local/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./.local/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./.local/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./.local/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./.local/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in ./.local/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./.local/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from requests->transformers) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.11/site-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from transformers) (3.13.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in ./.local/lib/python3.11/site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.11/site-packages (from transformers) (2.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /cluster/software/EL9/easybuild/software/PyYAML/6.0.1-GCCcore-13.2.0/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.local/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /cluster/software/EL9/easybuild/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from requests->transformers) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from requests->transformers) (2023.7.22)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: huggingface-hub in ./.local/lib/python3.11/site-packages (0.26.5)\n",
      "Requirement already satisfied: filelock in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from huggingface-hub) (3.13.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from huggingface-hub) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from huggingface-hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /cluster/software/EL9/easybuild/software/PyYAML/6.0.1-GCCcore-13.2.0/lib/python3.11/site-packages (from huggingface-hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from huggingface-hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.local/lib/python3.11/site-packages (from huggingface-hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /cluster/software/EL9/easybuild/software/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/site-packages (from huggingface-hub) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from requests->huggingface-hub) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from requests->huggingface-hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from requests->huggingface-hub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.10-GCCcore-13.2.0/lib/python3.11/site-packages (from requests->huggingface-hub) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install transformers torch accelerate bitsandbytes\n",
    "!pip install --upgrade transformers\n",
    "\n",
    "!pip install huggingface-hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6073e0-b4ef-41e0-a597-8b1576f0398f",
   "metadata": {},
   "source": [
    "## Authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da5da40d-cc0a-48cf-b49e-fca5b29fc7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "os.environ[\"HF_HOME\"] = \"/projects/ec12/ec-sindrre/cache\" \n",
    "\n",
    "# Put into env.config file\n",
    "access_token_read = os.environ.get('HF_API_KEY')\n",
    "login(token = access_token_read)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a3c3c-35ac-4f7f-836b-ed72851c222e",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b50df78-1de1-470c-b5aa-10c69228ebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set samples: 10\n",
      "Validation set samples: 3\n",
      "test set samples: 1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Load datasets\n",
    "def load_dataset(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "        \n",
    "num_shot = 10 # currently either 10 or 5 datasets\n",
    "\n",
    "train_data = load_dataset('./Data/Few-shot/train_' + str(num_shot) + '_shot.json')\n",
    "val_data = load_dataset('./Data/Few-shot/validation_' + str(num_shot) + '_shot.json')\n",
    "test_data = load_dataset('./Data/Few-shot/test_' + str(num_shot) + '_shot.json')\n",
    "\n",
    "# Extract prompts and library_functions (responses) from the dataset\n",
    "def extract_prompts_and_responses(data):\n",
    "    # Prompts from the first element of 'prompts', with additional instruction\n",
    "    prompts = [f\"Identify the library functions to be used in this example: {item['prompts'][0]}\\n {item['prompts'][1]}\" for item in data]\n",
    "    # Responses from the library_functions list\n",
    "    responses = [\", \".join(item[\"library_functions\"]) for item in data]\n",
    "    return prompts, responses\n",
    "\n",
    "def used_libraries_to_string(data):\n",
    "    name_doc_string = \"\"\n",
    "    for func in data:\n",
    "        name_doc_string += f\"Name: {func['function_name']}\\nDocumentation: {func['doc']}\\n\\n\"\n",
    "    return name_doc_string\n",
    "    \n",
    "# Extract training, validation, and test data\n",
    "train_prompts, train_responses = extract_prompts_and_responses(train_data)  # Use as examples for few-shot learning\n",
    "val_prompts, val_responses = extract_prompts_and_responses(val_data)  # Validation set\n",
    "test_prompts, test_responses = extract_prompts_and_responses(test_data)  # Test set\n",
    "\n",
    "\n",
    "# Extract all unique nodes (library_functions) across datasets\n",
    "used_libraries_json = load_dataset(\"./Data/Few-shot/libraries_\" + str(num_shot) + \"_shot.json\")\n",
    "explained_used_libraries = used_libraries_to_string(used_libraries_json)\n",
    "\n",
    "print(f\"train set samples: {len(train_prompts)}\")\n",
    "print(f\"Validation set samples: {len(val_prompts)}\")\n",
    "print(f\"test set samples: {len(test_prompts)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315b4428-6b24-441c-90da-44e03336f79d",
   "metadata": {},
   "source": [
    "## Create Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51ed17d-7b3a-469b-8da6-bfb763f9e532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create few-shot prompt\n",
    "def create_few_shot_prompt(train_prompts, train_responses, input_prompt):\n",
    "    Context = \"You are going to solve some programming tasks for node-based programming language. Use minimal amount of library functions to solve the tasks.\\n\" \n",
    "    node_list = f\"Only use the following library functions:\\n {explained_used_libraries}\\n\\n\"\n",
    "    formatted_prompt = node_list\n",
    "    for i, (prompt, response) in enumerate(zip(train_prompts, train_responses)):\n",
    "        formatted_prompt += f\"Example {i+1}:\\nPrompt: {prompt}\\nResponse: {response}\\n\\n\"\n",
    "    formatted_prompt += f\"Task:\\n{input_prompt}\\nResponse:\"\n",
    "    return formatted_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d05ea3-4062-48f7-94c9-51c0cfb96505",
   "metadata": {},
   "source": [
    "## Test some Models, with different seeds, temperatures, top_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b5510-e0d2-42ca-825e-0a43eb7e3d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "NVIDIA H100 PCIe MIG 1g.20gb\n",
      "Testing model: meta-llama/Meta-Llama-3.1-8B...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489050d3e05d4028af698e29a3bc490e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing with Seed: 3\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, set_seed\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.device_count())  # Should return the number of GPUs\n",
    "print(torch.cuda.current_device())  # Should return the current GPU index (e.g., 0)\n",
    "print(torch.cuda.get_device_name(0))  # Should return the name of your GPU\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch_dtype = torch.float16\n",
    "else:\n",
    "    torch_dtype = torch.float32  # Use FP32 on CPU\n",
    "\n",
    "# Function to generate and evaluate responses\n",
    "def evaluate_with_pipeline(pipeline, prompts, responses, max_new_tokens=50, temperature=0.7, top_p=0.9):\n",
    "    correct = 0\n",
    "    total = len(prompts)\n",
    "\n",
    "    for index, (prompt, true_response) in enumerate(zip(prompts, responses)):\n",
    "        full_prompt = create_few_shot_prompt(train_prompts, train_responses, prompt)\n",
    "        generated = pipeline(\n",
    "            full_prompt,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            return_full_text=False,\n",
    "            num_return_sequences=1,  # Ensure only one response\n",
    "        )[0][\"generated_text\"]\n",
    "        \n",
    "        print(f\"\\n\\nSample: {index}\")\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        print(f\"Generated response: {generated}\")\n",
    "        print(f\"True response: {true_response}\")\n",
    "\n",
    "         # Tokenize both responses into words\n",
    "        generated_words = set(generated.replace(\",\", \"\").split())\n",
    "        true_response_words = set(true_response.replace(\",\", \"\").split())\n",
    "        library_functions = set(item['function_name'] for item in used_libraries_json)\n",
    "        print(f\"Found these valid functions in output: {generated_words.intersection(library_functions)}\")\n",
    "        print(f\"Correct nodes is: {true_response_words}\")\n",
    "        # Check if there are any common words\n",
    "        if generated_words.intersection(library_functions) == true_response_words:\n",
    "            print(\"correct response\")\n",
    "            correct += 1\n",
    "        else:\n",
    "            print(\"Invalid response\")\n",
    "        \n",
    "    return correct / total\n",
    "\n",
    "# List of models to test\n",
    "models_to_test = [\n",
    "    {\"name\": \"meta-llama/Meta-Llama-3.1-8B\", \"cache_dir\": \"/projects/ec12/ec-sindrre/cache\"},\n",
    "    # {\"name\": \"mistralai/Mistral-Small-Instruct-2409\", \"cache_dir\": \"/projects/ec12/ec-sindrre/cache\"},\n",
    "    # {\"name\": \"meta-llama/Llama-3.3-70B-Instruct\", \"cache_dir\": \"/projects/ec12/ec-sindrre/cache\"},\n",
    "    # {\"name\": \"meta-llama/CodeLlama-70b-Instruct-hf\", \"cache_dir\": \"/projects/ec12/ec-sindrre/cache\"},\n",
    "    # {\"name\": \"meta-llama/Llama-3.2-90B-Vision-Instruct\", \"cache_dir\": \"/projects/ec12/ec-sindrre/cache\"}\n",
    "]\n",
    "results = {}\n",
    "seeds = [3, 75, 346]  # List of some random chosen seeds for consistent variability testing\n",
    "\n",
    "for model_info in models_to_test:\n",
    "    print(f\"Testing model: {model_info['name']}...\")\n",
    "\n",
    "    # Load model and tokenizer\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_info[\"name\"],\n",
    "        cache_dir=model_info[\"cache_dir\"],\n",
    "        torch_dtype=torch_dtype,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_info[\"name\"],\n",
    "        cache_dir=model_info[\"cache_dir\"]\n",
    "    )\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    # Create pipeline for the model\n",
    "    text_gen_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    # Test with different seeds\n",
    "    for seed in seeds:\n",
    "        print(f\"\\nTesting with Seed: {seed}\")\n",
    "        set_seed(seed)\n",
    "        \n",
    "        # Validation phase\n",
    "        temperatures = [0.5, 0.7, 0.9]\n",
    "        top_ps = [0.2, 0.5, 1.0]\n",
    "        best_accuracy = 0\n",
    "        best_params = {\"temperature\": 0.7, \"top_p\": 0.9}  # Default values\n",
    "        \n",
    "        for temp in temperatures:\n",
    "            for top_p in top_ps:\n",
    "                accuracy = evaluate_with_pipeline(text_gen_pipeline, val_prompts, val_responses, temperature=temp, top_p=top_p)\n",
    "                print(f\"Tested with temp={temp} and top_p={top_p}. Gave accuracy={accuracy}\")\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_params = {\"temperature\": temp, \"top_p\": top_p}\n",
    "    \n",
    "        print(f\"Best Hyperparameters for {model_info['name']}: {best_params}, Validation Accuracy: {best_accuracy:.2f}\")\n",
    "    \n",
    "        # Test phase\n",
    "        if not best_params:\n",
    "            print(\"No valid hyperparameters found during validation; using default values.\")\n",
    "            best_params = {\"temperature\": 0.7, \"top_p\": 0.9}\n",
    "        \n",
    "        test_accuracy = evaluate_with_pipeline(\n",
    "            text_gen_pipeline,\n",
    "            test_prompts,\n",
    "            test_responses,\n",
    "            temperature=best_params[\"temperature\"],\n",
    "            top_p=best_params[\"top_p\"]\n",
    "        )\n",
    "    \n",
    "        print(f\"Test Accuracy for {model_info['name']}: {test_accuracy:.2f}\")\n",
    "    \n",
    "        # Store results\n",
    "        if model_info[\"name\"] not in results:\n",
    "            results[model_info[\"name\"]] = []\n",
    "            results[model_info[\"name\"]].append({\n",
    "                \"seed\": seed,\n",
    "                \"validation_accuracy\": best_accuracy,\n",
    "                \"test_accuracy\": test_accuracy\n",
    "            })\n",
    "\n",
    "# Print summary of results\n",
    "print(\"\\nFinal Results:\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    for run in metrics:\n",
    "        print(f\"  Seed {run['seed']}: Validation Accuracy: {run['validation_accuracy']:.2f}, Test Accuracy: {run['test_accuracy']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
