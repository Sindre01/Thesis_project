{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "605d132a-e3b2-42ee-82a2-50ccefbc9139",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf93b4f-f9b0-4929-bd2c-4bb7688d8576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (22.0.2)\n",
      "Collecting pip\n",
      "  Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.0.2\n",
      "    Uninstalling pip-22.0.2:\n",
      "      Successfully uninstalled pip-22.0.2\n",
      "Successfully installed pip-24.3.1\n",
      "Requirement already satisfied: transformers in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (4.48.0)\n",
      "Requirement already satisfied: torch in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: accelerate in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: bitsandbytes in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (0.45.1)\n",
      "Requirement already satisfied: filelock in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: transformers in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (4.48.0)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: filelock in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from requests->transformers) (2024.12.14)\n",
      "Downloading transformers-4.48.1-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: huggingface-hub in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (0.27.1)\n",
      "Requirement already satisfied: filelock in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from huggingface-hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from huggingface-hub) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from huggingface-hub) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from huggingface-hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from huggingface-hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from huggingface-hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from huggingface-hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from requests->huggingface-hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from requests->huggingface-hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from requests->huggingface-hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (from requests->huggingface-hub) (2024.12.14)\n",
      "Requirement already satisfied: python-dotenv in /root/Thesis_project/.venv_Master/lib/python3.11/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install transformers torch accelerate bitsandbytes\n",
    "!pip install --upgrade transformers\n",
    "\n",
    "!pip install huggingface-hub\n",
    "!pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6073e0-b4ef-41e0-a597-8b1576f0398f",
   "metadata": {},
   "source": [
    "## Authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5da40d-cc0a-48cf-b49e-fca5b29fc7e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from config.env\n",
    "load_dotenv(\"../.env\")\n",
    "# print(\"HF_API_KEY:\", os.environ.get('HF_API_KEY'))  # This should print your token\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"/projects/ec12/ec-sindrre/cache\" \n",
    "\n",
    "# Put into env.config file\n",
    "access_token_read = os.environ.get('HF_API_KEY')\n",
    "login(token = access_token_read)\n",
    "\n",
    "if access_token_read:\n",
    "    login(token=access_token_read)\n",
    "    print(\"Logged in successfully!\")\n",
    "else:\n",
    "    print(\"HF_API_KEY is not set in your environment variables.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26a3c3c-35ac-4f7f-836b-ed72851c222e",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf6ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b50df78-1de1-470c-b5aa-10c69228ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.append('../')  # Add the path to the my_packages module\n",
    "from my_packages.data_processing.split_dataset import split_on_shots, split\n",
    "from my_packages.data_processing.get_labels_data import used_libraries_from_dataset\n",
    "from my_packages.analysis.analyze_datasets import analyze_library_distribution, analyze_instance_distribution, analyze_visual_node_types_distribution\n",
    "\n",
    "# main dataset\n",
    "with open('../data/mbpp_transformed_code_examples/sanitized-MBPP-midio.json', 'r') as file:\n",
    "    dataset = json.load(file)\n",
    "    \n",
    "num_shot = 10 # Few-shot examples\n",
    "eval_size_percentage = 0.5\n",
    "train_data, val_data, test_data = split_on_shots(num_shot, eval_size_percentage, dataset, seed = 64, write_to_file=True)\n",
    "\n",
    "def extract_prompts_and_responses(data):\n",
    "    prompts = [f\"Identify the library functions to be used in this example: {item['prompts'][0]}\\n \" for item in data]\n",
    "    # Responses from the library_functions list\n",
    "    responses = [\", \".join(item[\"library_functions\"]) for item in data]\n",
    "    return prompts, responses\n",
    "\n",
    "def used_libraries_to_string(data):\n",
    "    name_doc_string = \"\"\n",
    "    for func in data:\n",
    "        name_doc_string += f\"Name: {func['function_name']}\\nDocumentation: {func['doc']}\\n\\n\"\n",
    "    return name_doc_string\n",
    "    \n",
    "# Extract training, validation, and test data\n",
    "train_prompts, train_responses = extract_prompts_and_responses(train_data)  # Use as examples for few-shot learning\n",
    "val_prompts, val_responses = extract_prompts_and_responses(val_data)  # Validation set\n",
    "test_prompts, test_responses = extract_prompts_and_responses(test_data)  # Test set\n",
    "\n",
    "# Extract all unique nodes (library_functions) across datasets\n",
    "used_libraries_json = used_libraries_from_dataset(train_data)\n",
    "\n",
    "explained_used_libraries = used_libraries_to_string(used_libraries_json)\n",
    "\n",
    "print(f\"train set samples: {len(train_prompts)}\")\n",
    "print(f\"Validation set samples: {len(val_prompts)}\")\n",
    "print(f\"test set samples: {len(test_prompts)}\")\n",
    "\n",
    "#Bar chart of distribuation\n",
    "analyze_library_distribution(train_data, val_data, test_data)\n",
    "analyze_instance_distribution(train_data, val_data, test_data)\n",
    "analyze_visual_node_types_distribution(train_data, val_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315b4428-6b24-441c-90da-44e03336f79d",
   "metadata": {},
   "source": [
    "## Create Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d51ed17d-7b3a-469b-8da6-bfb763f9e532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create few-shot prompt\n",
    "def create_few_shot_prompt(train_prompts, train_responses, input_prompt):\n",
    "    Context = \"You are going to solve some programming tasks for node-based programming language. Use minimal amount of library functions to solve the tasks.\\n\" \n",
    "    node_list = f\"Only use the following library functions:\\n {explained_used_libraries}\\n\\n\"\n",
    "    formatted_prompt = Context + node_list\n",
    "    for i, (prompt, response) in enumerate(zip(train_prompts, train_responses)):\n",
    "        formatted_prompt += f\"Example {i+1}:\\nPrompt: {prompt}\\nResponse: {response}\\n\\n\"\n",
    "    formatted_prompt += f\"Task:\\n{input_prompt}\\nResponse:\"\n",
    "    return formatted_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d05ea3-4062-48f7-94c9-51c0cfb96505",
   "metadata": {},
   "source": [
    "## Test some Models, with different seeds, temperatures, top_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b5510-e0d2-42ca-825e-0a43eb7e3d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, set_seed\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())  # Should return True\n",
    "print(torch.cuda.device_count())  # Should return the number of GPUs\n",
    "print(torch.cuda.current_device())  # Should return the current GPU index (e.g., 0)\n",
    "print(torch.cuda.get_device_name(0))  # Should return the name of your GPU\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch_dtype = torch.float16\n",
    "else:\n",
    "    torch_dtype = torch.float32  # Use FP32 on CPU\n",
    "\n",
    "# Function to generate and evaluate responses\n",
    "def evaluate_with_pipeline(pipeline, prompts, responses, max_new_tokens=50, temperature=0.7, top_p=0.9):\n",
    "    correct = 0\n",
    "    total = len(prompts)\n",
    "\n",
    "    for index, (prompt, true_response) in enumerate(zip(prompts, responses)):\n",
    "        full_prompt = create_few_shot_prompt(train_prompts, train_responses, prompt)\n",
    "        generated = pipeline(\n",
    "            full_prompt,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            return_full_text=False,\n",
    "            num_return_sequences=1,  # Ensure only one response\n",
    "        )[0][\"generated_text\"]\n",
    "        \n",
    "        print(f\"\\n\\nSample: {index}\")\n",
    "        print(f\"Prompt: {prompt}\")\n",
    "        print(f\"Generated response: {generated}\")\n",
    "        print(f\"True response: {true_response}\")\n",
    "\n",
    "         # Tokenize both responses into words\n",
    "        generated_words = set(generated.replace(\",\", \"\").split())\n",
    "        true_response_words = set(true_response.replace(\",\", \"\").split())\n",
    "        library_functions = set(item['function_name'] for item in used_libraries_json)\n",
    "        print(f\"Found these valid functions in output: {generated_words.intersection(library_functions)}\")\n",
    "        print(f\"Correct nodes is: {true_response_words}\")\n",
    "        # Check if there are any common words\n",
    "        if true_response_words.issubset(generated_words.intersection(library_functions)):\n",
    "            print(\"correct response\")\n",
    "            correct += 1\n",
    "        else:\n",
    "            print(\"Invalid response\")\n",
    "        \n",
    "    return correct / total\n",
    "\n",
    "# List of models to test\n",
    "models_to_test = [\n",
    "    #{\"name\": \"meta-llama/Meta-Llama-3.1-8B\", \"cache_dir\": \"/projects/ec12/ec-sindrre/cache\"},\n",
    "    {\"name\": \"mistralai/Mistral-Small-Instruct-2409\", \"cache_dir\": \"/projects/ec12/ec-sindrre/cache\"},\n",
    "    # {\"name\": \"meta-llama/Llama-3.3-70B-Instruct\", \"cache_dir\": \"/projects/ec12/ec-sindrre/cache\"},\n",
    "    # {\"name\": \"meta-llama/CodeLlama-70b-Instruct-hf\", \"cache_dir\": \"/projects/ec12/ec-sindrre/cache\"},\n",
    "    # {\"name\": \"meta-llama/Llama-3.2-90B-Vision-Instruct\", \"cache_dir\": \"/projects/ec12/ec-sindrre/cache\"}\n",
    "]\n",
    "results = {}\n",
    "seeds = [3, 75, 346]  # List of some random chosen seeds for consistent variability testing\n",
    "\n",
    "for model_info in models_to_test:\n",
    "    print(f\"Testing model: {model_info['name']}...\")\n",
    "\n",
    "    # Load model and tokenizer\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_info[\"name\"],\n",
    "        cache_dir=model_info[\"cache_dir\"],\n",
    "        torch_dtype=torch_dtype,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_info[\"name\"],\n",
    "        cache_dir=model_info[\"cache_dir\"]\n",
    "    )\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    # Create pipeline for the model\n",
    "    text_gen_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        torch_dtype=torch_dtype,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    # Test with different seeds. FLYTT SEEDS NED TIL TESTING DELEN!!\n",
    "    for seed in seeds:\n",
    "        print(f\"\\nTesting with Seed: {seed}\")\n",
    "        set_seed(seed)\n",
    "        \n",
    "        # Validation phase\n",
    "        temperatures = [0.5, 0.7, 0.9]\n",
    "        top_ps = [0.2, 0.5, 1.0]\n",
    "        best_accuracy = 0\n",
    "        best_params = {\"temperature\": 0.7, \"top_p\": 0.9}  # Default values\n",
    "        \n",
    "        for temp in temperatures:\n",
    "            for top_p in top_ps:\n",
    "                accuracy = evaluate_with_pipeline(text_gen_pipeline, val_prompts, val_responses, temperature=temp, top_p=top_p)\n",
    "                print(f\"Tested with temp={temp} and top_p={top_p}. Gave accuracy={accuracy}\")\n",
    "                if accuracy > best_accuracy:\n",
    "                    best_accuracy = accuracy\n",
    "                    best_params = {\"temperature\": temp, \"top_p\": top_p}\n",
    "    \n",
    "        print(f\"Best Hyperparameters for {model_info['name']}: {best_params}, Validation Accuracy: {best_accuracy:.2f}\")\n",
    "    \n",
    "        # Test phase\n",
    "        if not best_params:\n",
    "            print(\"No valid hyperparameters found during validation; using default values.\")\n",
    "            best_params = {\"temperature\": 0.7, \"top_p\": 0.9}\n",
    "        \n",
    "        test_accuracy = evaluate_with_pipeline(\n",
    "            text_gen_pipeline,\n",
    "            test_prompts,\n",
    "            test_responses,\n",
    "            temperature=best_params[\"temperature\"],\n",
    "            top_p=best_params[\"top_p\"]\n",
    "        )\n",
    "    \n",
    "        print(f\"Test Accuracy for {model_info['name']}: {test_accuracy:.2f}\")\n",
    "    \n",
    "        # Store results\n",
    "        if model_info[\"name\"] not in results:\n",
    "            results[model_info[\"name\"]] = []\n",
    "            results[model_info[\"name\"]].append({\n",
    "                \"seed\": seed,\n",
    "                \"validation_accuracy\": best_accuracy,\n",
    "                \"test_accuracy\": test_accuracy\n",
    "            })\n",
    "\n",
    "# Print summary of results\n",
    "print(\"\\nFinal Results:\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}:\")\n",
    "    for run in metrics:\n",
    "        print(f\"  Seed {run['seed']}: Validation Accuracy: {run['validation_accuracy']:.2f}, Test Accuracy: {run['test_accuracy']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_Master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
