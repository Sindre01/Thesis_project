[
    {
        "model_name": "llama3.2:3b-instruct-fp16",
        "optimizer_metric": "syntax",
        "seed": 9,
        "temperature": 0.9,
        "top_p": 0.9,
        "top_k": 50,
        "created_at": "2025-04-21T15:14:56.715875+02:00",
        "syntax@1": 1.0
    },
    {
        "model_name": "llama3.2:3b-instruct-fp16",
        "optimizer_metric": "semantic",
        "seed": 9,
        "temperature": 0.2,
        "top_p": 0.9,
        "top_k": 50,
        "created_at": "2025-04-21T15:15:32.581182+02:00",
        "semantic@1": 0.6666666666666666
    },
    {
        "model_name": "llama3.2:3b-instruct-fp16",
        "optimizer_metric": "tests",
        "seed": 9,
        "temperature": 0.2,
        "top_p": 0.6,
        "top_k": 10,
        "created_at": "2025-04-21T15:16:21.130978+02:00",
        "tests@1": 0.3333333333333333
    },
    {
        "model_name": "llama3.2:3b-instruct-fp16",
        "optimizer_metric": "syntax",
        "seed": 9,
        "temperature": 0.9,
        "top_p": 0.9,
        "top_k": -1,
        "created_at": "2025-04-22T12:42:20.237091+02:00",
        "syntax@1": 1.0
    },
    {
        "model_name": "llama3.2:3b-instruct-fp16",
        "optimizer_metric": "semantic",
        "seed": 9,
        "temperature": 0.2,
        "top_p": 0.6,
        "top_k": -1,
        "created_at": "2025-04-22T12:42:30.139657+02:00",
        "semantic@1": 0.4444444444444444
    },
    {
        "model_name": "llama3.2:3b-instruct-fp16",
        "optimizer_metric": "tests",
        "seed": 9,
        "temperature": 0.2,
        "top_p": 0.9,
        "top_k": -1,
        "created_at": "2025-04-22T12:42:42.723322+02:00",
        "tests@1": 0.3333333333333333
    }
]