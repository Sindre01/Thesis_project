{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Mean Overall Score: 0.9350712250712251\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import List, Dict, Any\n",
    "import sys\n",
    "sys.path.append('../../')  # Add the path to the my_packages module\n",
    "from my_packages.evaluation.nodes_flow_metric import evaluate_nodes_flow\n",
    "from my_packages.utils.file_utils import get_train_task_ids, read_code_file\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# code = read_code_file(1)  # assuming this returns the code as a string\n",
    "# code = \"\"\"\" \n",
    "# import(\"std\", Std_k98ojb)\n",
    "# import(\"http\", Http_q7o96c)\n",
    "\n",
    "# module() main {\n",
    "#     func() min_of_three {\n",
    "#         in(x: -769.6855759900376, y: -411.0358560546829, name: \"a\") property(Number) a_f37c19\n",
    "#         in(x: -775.4615926769588, y: -311.94665736242496, name: \"b\") property(Number) b_ca79ac\n",
    "#         in(x: -772.4906914682103, y: -226.85470946491404, name: \"c\") property(Number) c_a89f71\n",
    "\n",
    "#         out(x: -59.0875497141829, y: -332.1206884918196, name: \"min\")  property(Number) smallest_8713cf\n",
    "\n",
    "#         data_instance(x: -517.8, y: -342.4, stableId: \"y12hm245bcs4zl39zu4wyfw9\") data_9a9c70  = [\n",
    "#                 a,\n",
    "#                 b,\n",
    "#                 c\n",
    "#             ]\n",
    "#         instance(x: -293.0, y: -323.6) min_c3e343 root.Std_k98ojb.List.Min {}\n",
    "#         a_f37c19 -> data_9a9c70.a\n",
    "#         b_ca79ac -> data_9a9c70.b\n",
    "#         c_a89f71 -> data_9a9c70.c\n",
    "#         min_c3e343.min -> smallest_8713cf\n",
    "#         data_9a9c70 -> min_c3e343.items\n",
    "#     }\n",
    "# }\n",
    "# \"\"\"\n",
    "# print(\"Full Code:\")\n",
    "# print(code)\n",
    "# score = evaluate_nodes_flow(code_snippet=code)\n",
    "\n",
    "\n",
    "tests_task_ids = get_train_task_ids()\n",
    "\n",
    "sum = 0\n",
    "for i in tests_task_ids:\n",
    "    code = read_code_file(i+1)\n",
    "    overall_score = evaluate_nodes_flow(code_snippet=code)\n",
    "    sum += overall_score\n",
    "    if overall_score < 0.5:\n",
    "        print(f\"Warning: Overall score for task {i+1} is {overall_score} less than 1.0. Check the code snippet for issues.\")\n",
    "    #     print(code)\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(\"Mean Overall Score:\", sum / len(tests_task_ids))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_Master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
